[TOC]

<img src="https://flyman-cjb.oss-cn-hangzhou.aliyuncs.com/picgos/20190406173739.png" width="700" height="高度" alt="图片名称" align=center>

想要做到极致速度就需要一个高速的数据流，也就是pipeline。这个有什么用呢？比如说：

1. **文件转换二进制格式**

   图片大多以JPG等格式存储，我们可以提前转化为二进制`Tensor`，降低读取开销，提升读取效率。

2. **提前准备训练数据**

   每个训练批次下，GPU都要等待CPU增强完数据之后才可以操作，反过来也是，训练时候CPU又空闲。这段时间完全可以利用起来，避免设备闲置。

3. **利用多核CPU预处理**

   由于Python的GIL锁限制，大多数时候数据增强只能用到CPU中的一个核心，我们完全可以利用CPU多个核心进行数据增强。

4. **并行IO读取数据**

   分布式训练时候，虽然网络传输带宽很大，但是单个文件的读取速度可能很慢，我们想把它并行化，有效利用带宽降低延迟。

TensorFlow1.x 给了很多方法来读取数据，比如说`Queue` 、`QueueRunner`什么的。但又何苦呢？人生苦短，爸爸不想写代码。

> 爸爸只是想快一点读取数据，快一点训练网络。需求最多也就是，我这个机房有10台服务器，每个服务器有4张1080ti，现在怎样方便地将数据或者模型分发下去进行分布式的数据预处理以及网络训练？

那么如果你想要实现非常方便高效地并且能够分布式地读取数据训练模型，那么你就应该用`tf.data`API，而不是难用到吐血的队列！

# 01 TFRecord文件写入与读取

## 1.1 TFRecord基本机制

TFRecord文件是官方推荐的一种二进制文件格式，简单说包含了一系列键值对，需要注意的是，这些值必须都是列表形式，事实上它们属于`protocolbuf`通用协议，所以不光在Python中可以解析他们，在其他语言中也可以解析。而在Python语言中对应的是列表，在Java/C/C++中对应的就是数组。还有一点需要注意：

> 一个 **BytesList** 可以存储Byte数组，因此不论是字符串、图片视频等等都可以容纳进去。以BytesList格式存储图像数据有个好处是不需要存储shape信息，我们解压之后就变为我们想要的。

所以图像我们都是以BytesList存储的。目前，TFRecord文件是以下面的方式组织数据存储的：

<img src="https://flyman-cjb.oss-cn-hangzhou.aliyuncs.com/picgos/20190409154929.png" width="宽度" height="高度" alt="图片名称" align=center>

而`tf.train.Feature`中能够存储的数据类型非常广泛：

<img src="https://flyman-cjb.oss-cn-hangzhou.aliyuncs.com/picgos/20190409135444.png" width="宽度" height="高度" alt="图片名称" align=center>

## 1.2 文件写入

下面是一个典型的图像写为tfrecord数据流的代码，注意`tf.train.Feature`里面的`value`必须是列表：

```python
def _parser_xml(xml_file):
        tree = ET.parse(xml_file)
        objs = tree.findall('object')
        label = []
        for obj in objs:
            category = obj.find('name').text.lower().strip()
            class_id = Class_to_index[category]
            bndbox = obj.find('bndbox')
            x1 = bndbox.find('xmin').text
            y1 = bndbox.find('ymin').text
            x2 = bndbox.find('xmax').text
            y2 = bndbox.find('ymax').text
            label.extend([x1, y1, x2, y2, class_id])
        return map(float, label)
```

<img src="https://flyman-cjb.oss-cn-hangzhou.aliyuncs.com/picgos/20190409155722.png" width="宽度" height="高度" alt="图片名称" align=center>

现在我们来总结一下：

1. `io.TFRecordWriter`打开文件

2. `open(file, 'rb').read()`以二进制形式读取文件

3. ```python
   example = tf.train.Features(feature={
       "key": tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])),
       ..............
   })
   ```

4. `writer.write(example.SerialieToString())`

## 1.3 文件解析

制作完成之后需要解析，一般是这样解析的：

```python
# 1. tf.data.TFRecordDataset加载
_dataset = tf.data.TFRecordDataset(os.path.join(self.folder, self.usage + '.tfrecords'))
# 2. map解析
_dataset = _dataset.map(Dataset._parse, num_parallel_calls=tfde.AUTOTUNE)
```

```python
def _parse(example):
        features = {'image': tf.io.FixedLenFeature((), tf.string, ""),
                    # 因为label有长有短，因此是变化的
                    'label': tf.io.VarLenFeature(tf.float32)}
        features = tf.io.parse_single_example(example, features)
        image = tf.image.decode_jpeg(features['image'])
        label = features['label'].values
        return image, label
```

# 02 高性能方法

最简单的Pipeline代码如下：

```python
def make_dataset():
  dataset = tf.data.TFRecordDataset("/path/to/dataset/train-*.tfrecord")
  dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size)
  dataset = dataset.map(map_func=parse_fn)
  dataset = dataset.batch(batch_size=FLAGS.batch_size)
  return dataset
```

但是这样写读取速度太慢了，为什么？正如开头所说的，没有多进程IO，多进程数据增强、数据缓存到内存，提前准备数据，TensorFlow空有一身蛮力根本没有发挥出来。

## 2.1 提前准备数据

在一个简单的同步执行中，当 CPU 正在准备数据时，加速器则处于空闲状态。相反，当加速器正在训练模型时，CPU 则处于空闲状态。

如果没有使用 pipelining，则 CPU 和 GPU / TPU 在大部分时间处于闲置状态：

![img](https://mmbiz.qpic.cn/mmbiz_png/NkE3uMFiafXEXuoRZTAGB8SJQhGUGv0x4vSDySKDnwKicGw8fowuWsYyTtoxMRiafrrFqXmPRGzPmiag0YKYLLpOWQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

而使用 pipelining 技术后，空闲时间显著减少：

![img](https://mmbiz.qpic.cn/mmbiz_png/NkE3uMFiafXEXuoRZTAGB8SJQhGUGv0x4hyrUuqiauRWmP2uHVzQAibS1z50ibwwpK7a4SKI8ks5FvicERWMgpYR6dA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

`tf.data`API 提供了一个软件流水线机制，可以让你节约这个时间。实际上，这个转换通过一个后台线程以及内部缓冲区 来提前获取数据。有两点需要注意：

- 获取的数量应该大于等于单个训练步骤下的Batchsize。
- 你可以通过手动或者`tf.data.experimental.AUTOTUNE` 去动态的管理。

你只需要在流水线的 **最后添加这么一段代码**：

```python
dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
```

## 2.2 并行预处理

单核心CPU->多核心CPU：

![img](https://tensorflow.google.cn/images/datasets_parallel_map.png)

```python
# 修改之前
dataset = dataset.map(map_func=parse_fn)
# 修改之后
dataset = dataset.map(map_func=parse_fn,
                      num_parallel_calls=tf.data.experimental.AUTOTUNE)
```

## 2.3 并行IO读取

有些数据是远程存储的，例如(GCS 和 HDFS)，并且训练可能是分布式的，这和单机训练存在很大差异。虽然远程存储通常提供较大的聚合带宽，但是读取单个文件可能只使用一小部分，我们并行化处理：

```python
# 修改之前
dataset = tf.data.TFRecordDataset("/path/to/dataset/train-*.tfrecord")
# 修改之后
files = tf.data.Dataset.list_files("/path/to/dataset/train-*.tfrecord")
dataset = files.interleave(tf.data.TFRecordDataset,                                                        cycle_length=FLAGS.num_parallel_reads,                               num_parallel_calls=tf.data.experimental.AUTOTUNE)
```

## 2.4 进一步优化

### 2.4.1 map开销很小时，batch形式的map更高效

将用户自定义的函数传给 `map` 函数 会产生调度、执行用户自定义函数的负载。

- 一般情况下，这个负载与自定义函数的计算量相比很小。
- 但是，如果 map 的函数的计算量很小，这个负载将是主要开销。

在这种情况下，我们推荐使用向量化的自定义函数（它一次对一个batch进行变换），并且在` map `变换前使用 `batch` 变换。

### 2.4.2 Map and Cache ------ 通过cache进一步加速

`tf.data.Dataset.cache` 变化能够在内存或本地存储器上缓存一个数据集。如果传递给 map 变换的用户自定义函数的计算量很大，只要得到的数据集仍然适合内存或本地存储，就可以在 **map 转换之后应用 cache 转换**。

- 如果用户定义函数导致存储数据集需要的空间超过了 cache 的容量，考虑提前对数据集进行预处理，以减少资源的使用。

cache将数据集进行缓存能够有效地提高数据输入管道的性能，但是，cache位置放置错误时，会导致模型性能下降。

### 2.4.3 Repeat and Shuffle

如果`repeat`在`shuffle`之前，那么每一轮的界限是模糊的。也就是说，某些元素可以在其他元素出现之前重复出现一次。如果`shuffle`在`repeat`之前，如果epoch开始时候性能可能会下降。

换句话说，洗牌前重复提供了更好的性能，而重复之前洗牌提供了更好的次序，可以使用:

```python
_dataset = _dataset.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=512))
```

## 2.5 高性能实现

```python
def __call__(self, batchsize=32):
        # 1 多进程读取 对单个文件也有效
        files = tf.data.Dataset.list_files(os.path.join(self.folder,
                                                        self.usage + '.tfrecords'))
        _dataset = files.interleave(tf.data.TFRecordDataset, cycle_length=2,
                                    num_parallel_calls=tf.data.experimental.AUTOTUNE)
 
        # 2. 多进程预处理
        _dataset = _dataset.map(Dataset._parse, num_parallel_calls=tfde.AUTOTUNE)
        # 3. 缓存数据到内存
        _dataset = _dataset.cache()
        _dataset = _dataset.apply(tf.data.experimental.
                                  shuffle_and_repeat(buffer_size=512))
        # 多进程预处理
        _dataset = _dataset.map(lambda image, label:
                                tf.py_function(func=self._process,
                                               inp=[image, label],
                                               Tout=[tf.float32, tf.float32]),
                                num_parallel_calls=tfde.AUTOTUNE)
        _dataset = _dataset.batch(batchsize)
        # 4. 提前准备数据
        _dataset = _dataset.prefetch(tfde.AUTOTUNE)
        return _dataset

```

效率可能也不是最高的，因为对每个文件来说大小、批次也都不一样，但是确实这样能够提升效率。还有个需要注意的是，`cycle_length`这个参数并不是越大越好，选择合适的。

# 03 高效读取数据总结

为什么我花费那么多时间给大家画图，我就希望大家记起来的时候有个直观的图形印象不容易忘记。请查看思维导图。

<img src="https://flyman-cjb.oss-cn-hangzhou.aliyuncs.com/picgos/20190409163122.png" width="宽度" height="高度" alt="图片名称" align=center>